services:
  # Main development container with Node.js, Next.js, and AI tools
  app:
    build:
      context: .devcontainer
      dockerfile: Dockerfile
      args:
        TZ: ${TZ:-America/Los_Angeles}
    volumes:
      - .:/workspace:cached
      - claude-code-bashhistory:/commandhistory
      - ~/.claude:/home/node/.claude:ro
      - node_modules:/workspace/node_modules
    environment:
      - NODE_OPTIONS=--max-old-space-size=4096
      - CLAUDE_CONFIG_DIR=/home/node/.claude
      - POWERLEVEL9K_DISABLE_GITSTATUS=true
      # Supabase connection
      - NEXT_PUBLIC_SUPABASE_URL=http://kong:8000
      - NEXT_PUBLIC_SUPABASE_ANON_KEY=${ANON_KEY}
      - SUPABASE_SERVICE_KEY=${SERVICE_ROLE_KEY}
    ports:
      - "3000:3000"  # Next.js
      - "3001:3001"  # Next.js HMR
    cap_add:
      - NET_ADMIN
      - NET_RAW
    command: sleep infinity
    networks:
      - supabase
    depends_on:
      - db
      - kong

  # PostgreSQL database
  db:
    image: supabase/postgres:15.1.0.147
    healthcheck:
      test: pg_isready -U postgres -h localhost
      interval: 5s
      timeout: 5s
      retries: 10
    command:
      - postgres
      - -c
      - config_file=/etc/postgresql/postgresql.conf
      - -c
      - log_min_messages=fatal
    environment:
      POSTGRES_HOST: /var/run/postgresql
      PGPORT: 5432
      POSTGRES_PORT: 5432
      PGPASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATABASE: postgres
      POSTGRES_DB: postgres
      PGUSER: supabase_admin
      SUPABASE_ADMIN_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./volumes/db/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./volumes/db/init:/docker-entrypoint-initdb.d
    networks:
      - supabase

  # Supabase Studio
  studio:
    image: supabase/studio:20240422-5cf8f30
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/api/profile', (r) => {if (r.statusCode !== 200) throw new Error(r.statusCode)})"]
      timeout: 5s
      interval: 5s
      retries: 3
    ports:
      - "54321:3000"
    environment:
      STUDIO_PG_META_URL: http://postgres-meta:8080
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DEFAULT_ORGANIZATION_NAME: Barel Dev
      DEFAULT_PROJECT_NAME: Barel Project
      SUPABASE_URL: http://kong:8000
      SUPABASE_PUBLIC_URL: http://localhost:8000
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      LOGFLARE_URL: http://analytics:4000
      LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
      NEXT_PUBLIC_ENABLE_LOGS: true
      NEXT_ANALYTICS_BACKEND_PROVIDER: postgres
    networks:
      - supabase
    # depends_on:
    #   analytics:
    #     condition: service_healthy

  # Kong API Gateway
  kong:
    image: kong:2.8.1
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 10s
      timeout: 10s
      retries: 10
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /usr/local/kong/kong.yml
      KONG_DNS_ORDER: LAST,A,CNAME
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      DASHBOARD_USERNAME: ${DASHBOARD_USERNAME}
      DASHBOARD_PASSWORD: ${DASHBOARD_PASSWORD}
    volumes:
      - ./volumes/api/kong.yml:/usr/local/kong/kong.yml:ro
    ports:
      - "8000:8000/tcp"
    networks:
      - supabase
    # depends_on:
    #   analytics:
    #     condition: service_healthy

  # GoTrue Auth
  auth:
    image: supabase/gotrue:v2.149.0
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9999/health"]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      GOTRUE_API_HOST: 0.0.0.0
      GOTRUE_API_PORT: 9999
      API_EXTERNAL_URL: ${API_EXTERNAL_URL}
      GOTRUE_DB_DRIVER: postgres
      GOTRUE_DB_DATABASE_URL: postgres://supabase_auth_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      GOTRUE_SITE_URL: ${SITE_URL}
      GOTRUE_URI_ALLOW_LIST: ${ADDITIONAL_REDIRECT_URLS}
      GOTRUE_DISABLE_SIGNUP: ${DISABLE_SIGNUP}
      GOTRUE_JWT_ADMIN_ROLES: service_role
      GOTRUE_JWT_AUD: authenticated
      GOTRUE_JWT_DEFAULT_GROUP_NAME: authenticated
      GOTRUE_JWT_EXP: ${JWT_EXPIRY}
      GOTRUE_JWT_SECRET: ${JWT_SECRET}
      GOTRUE_EXTERNAL_EMAIL_ENABLED: ${ENABLE_EMAIL_SIGNUP}
      GOTRUE_MAILER_AUTOCONFIRM: ${ENABLE_EMAIL_AUTOCONFIRM}
      GOTRUE_SMTP_ADMIN_EMAIL: ${SMTP_ADMIN_EMAIL}
      GOTRUE_SMTP_HOST: ${SMTP_HOST}
      GOTRUE_SMTP_PORT: ${SMTP_PORT}
      GOTRUE_SMTP_USER: ${SMTP_USER}
      GOTRUE_SMTP_PASS: ${SMTP_PASS}
      GOTRUE_SMTP_SENDER_NAME: ${SMTP_SENDER_NAME}
      GOTRUE_EXTERNAL_PHONE_ENABLED: ${ENABLE_PHONE_SIGNUP}
      GOTRUE_SMS_AUTOCONFIRM: ${ENABLE_PHONE_AUTOCONFIRM}
    networks:
      - supabase
    depends_on:
      db:
        condition: service_healthy

  # Realtime
  realtime:
    image: supabase/realtime:v2.28.32
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/api/tenants/realtime-dev/health"]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      PORT: 4000
      DB_HOST: ${POSTGRES_HOST}
      DB_PORT: ${POSTGRES_PORT}
      DB_USER: supabase_admin
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: ${POSTGRES_DB}
      DB_AFTER_CONNECT_QUERY: 'SET search_path TO _realtime'
      DB_ENC_KEY: supabaserealtime
      API_JWT_SECRET: ${JWT_SECRET}
      FLY_ALLOC_ID: fly123
      FLY_APP_NAME: realtime
      SECRET_KEY_BASE: UpNVntn3cDxHJpq99YMc1T1AQgQpc8kfYTuRgBiYa15BLrx8etQoXz3gZv1/u2oq
      ERL_AFLAGS: -proto_dist inet_tcp
      ENABLE_TAILSCALE: "false"
      DNS_NODES: "''"
    command: sh -c "/app/bin/migrate && /app/bin/realtime eval 'Realtime.Release.seeds(Realtime.Repo)' && /app/bin/server"
    networks:
      - supabase
    depends_on:
      db:
        condition: service_healthy

  # Storage
  storage:
    image: supabase/storage-api:v0.46.4
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5000/status"]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      ANON_KEY: ${ANON_KEY}
      SERVICE_KEY: ${SERVICE_ROLE_KEY}
      POSTGREST_URL: http://rest:3000
      PGRST_JWT_SECRET: ${JWT_SECRET}
      DATABASE_URL: postgres://supabase_storage_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      FILE_SIZE_LIMIT: 52428800
      STORAGE_BACKEND: file
      FILE_STORAGE_BACKEND_PATH: /var/lib/storage
      TENANT_ID: stub
      REGION: stub
      GLOBAL_S3_BUCKET: stub
      ENABLE_IMAGE_TRANSFORMATION: "true"
      IMGPROXY_URL: http://imgproxy:8080
    volumes:
      - storage-data:/var/lib/storage
    networks:
      - supabase
    depends_on:
      db:
        condition: service_healthy
      rest:
        condition: service_started
      imgproxy:
        condition: service_started

  # Image Proxy
  imgproxy:
    image: darthsim/imgproxy:v3.8.0
    healthcheck:
      test: ["CMD", "imgproxy", "health"]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      IMGPROXY_BIND: ":8080"
      IMGPROXY_LOCAL_FILESYSTEM_ROOT: /
      IMGPROXY_USE_ETAG: "true"
      IMGPROXY_ENABLE_WEBP_DETECTION: ${IMGPROXY_ENABLE_WEBP_DETECTION}
    volumes:
      - storage-data:/var/lib/storage:ro
    networks:
      - supabase

  # PostgREST
  rest:
    image: postgrest/postgrest:v11.2.2
    environment:
      PGRST_DB_URI: postgres://authenticator:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      PGRST_DB_SCHEMAS: ${PGRST_DB_SCHEMAS}
      PGRST_DB_ANON_ROLE: anon
      PGRST_JWT_SECRET: ${JWT_SECRET}
      PGRST_DB_USE_LEGACY_GUCS: "false"
      PGRST_APP_SETTINGS_JWT_SECRET: ${JWT_SECRET}
      PGRST_APP_SETTINGS_JWT_EXP: ${JWT_EXPIRY}
    networks:
      - supabase
    depends_on:
      db:
        condition: service_healthy

  # PostgreSQL Meta
  postgres-meta:
    image: supabase/postgres-meta:v0.80.0
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8080"]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      PG_META_PORT: 8080
      PG_META_DB_HOST: ${POSTGRES_HOST}
      PG_META_DB_PORT: ${POSTGRES_PORT}
      PG_META_DB_NAME: ${POSTGRES_DB}
      PG_META_DB_USER: supabase_admin
      PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD}
    networks:
      - supabase
    depends_on:
      db:
        condition: service_healthy

  # Edge Functions
  edge-runtime:
    image: supabase/edge-runtime:v1.45.2
    environment:
      JWT_SECRET: ${JWT_SECRET}
      SUPABASE_URL: http://kong:8000
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}
      SUPABASE_DB_URL: postgresql://postgres:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      VERIFY_JWT: "${FUNCTIONS_VERIFY_JWT}"
    volumes:
      - ./volumes/functions:/home/deno/functions:ro
    networks:
      - supabase
    # depends_on:
    #   analytics:
    #     condition: service_healthy

  # Analytics (Optional - disabled by default due to complexity)
  # Uncomment to enable analytics
  # analytics:
  #   image: supabase/logflare:1.4.0
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
  #     timeout: 10s
  #     interval: 10s
  #     retries: 10
  #   environment:
  #     LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
  #     LOGFLARE_SINGLE_TENANT: true
  #     LOGFLARE_SUPABASE_MODE: true
  #     LOGFLARE_NODE_HOST: 127.0.0.1
  #     DB_USERNAME: supabase_admin
  #     DB_DATABASE: ${POSTGRES_DB}
  #     DB_HOSTNAME: ${POSTGRES_HOST}
  #     DB_PORT: ${POSTGRES_PORT}
  #     DB_PASSWORD: ${POSTGRES_PASSWORD}
  #     DB_SCHEMA: _analytics
  #     POSTGRES_BACKEND_URL: postgresql://supabase_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
  #     POSTGRES_BACKEND_SCHEMA: _analytics
  #     LOGFLARE_FEATURE_FLAG_OVERRIDE: multibackend=true
  #   networks:
  #     - supabase
  #   depends_on:
  #     db:
  #       condition: service_healthy

  # Vector for logs
  vector:
    image: timberio/vector:0.28.1-alpine
    healthcheck:
      test: ["CMD", "vector", "top", "--url", "http://localhost:8686/graphql"]
      timeout: 5s
      interval: 5s
      retries: 3
    volumes:
      - ./volumes/logs/vector.yml:/etc/vector/vector.yml:ro
      - vector-data:/var/lib/vector
    environment:
      LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
    command: ["--config", "/etc/vector/vector.yml"]
    networks:
      - supabase
    # depends_on:
    #   analytics:
    #     condition: service_healthy

networks:
  supabase:
    driver: bridge

volumes:
  postgres-data:
  storage-data:
  node_modules:
  claude-code-bashhistory:
  vector-data: